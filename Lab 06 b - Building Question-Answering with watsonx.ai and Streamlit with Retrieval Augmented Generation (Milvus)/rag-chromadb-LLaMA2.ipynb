{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb570d8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Retrieval Augmented Generation(RAG)란?\n",
    "파운데이션 모델을 특정 도메인에 대해 파인 튜닝(Fine-tuning)할 경우 모델의 성능을 크게 개선시킬 수 있지만 데이터 수집부터 학습에 사용해야 하는 클라우드 서버 대여까지 큰 비용이 발생합니다. 일례로 BloombergGPT의 경우 약 700B개(약 7000억개)의 토큰을 학습에 사용하였고, LLaMA2가 2조개의 토큰을 학습에 사용하였습니다. 보통 일반적인 PDF문서가 1000개의 토큰을 가지고 있다고 가정하면, 특정 도메인의 파운데이션 모델을 만드는데 약 7억장의 문서가 필요한 셈입니다. 파인 튜닝에 필요한 데이터가 이정도로 필요한 것은 아니지만, 특정 도메인에 맞춰서 새롭게 파인튜닝을 할 때 기존 학습데이터의 0.01%만큼만 쓴다고 하더라도 7만장이 필요하게 됩니다.  반대로 RAG는 유저가 사용하는 프롬프트에 추가하고 싶은 데이터를 모델에 관계없이 적용시킬 수 있어 값비싼 파인 튜닝 없이 LLM을 보다 효율적으로 사용할 수 있습니다.\n",
    "\n",
    "RAG를 사용하면 기업은 데이터 관련성을 유지하고 비용을 최적화하면서 사용자 지정 솔루션을 달성할 수 있습니다. RAG를 채택함으로써 회사는 LLM의 추론 기능을 사용하고 기존 모델을 활용하여 새로운 데이터를 기반으로 응답을 처리하고 생성할 수 있습니다. RAG는 미세 조정 없이 정기적인 데이터 업데이트를 촉진하여 LLM을 비즈니스에 효율적으로 통합합니다.RAG는 다음과 같은 단계를 필요로 합니다:\n",
    "\n",
    "1. 문서를 청크 단위로 세분화\n",
    "2. 세분화한 문서 청크에서 자연어 임베딩 생성후 DB에 인덱싱\n",
    "3. 사용자의 쿼리(질문)에 대한에 대한 벡터 임베딩 생성.\n",
    "4. 벡터 유사도 검색을 사용자 쿼리와 자연어 임베딩 DB에서 관련 문서 검색경로 검벡터 유사도 검색을 사용하여 유사하다고 생각되는 top K개의 문서 청크를 프롬프트에 연결\n",
    "\n",
    "아래에서 위의 각 단계를 확인할 수 있습니다.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/rag-architecture-basic.png\" width=\"600\"/>\n",
    "</p>\n",
    "\n",
    "### Embeddings and Vector   \n",
    "RAG에서 사용되는 현재 최신 기법중 하나는 주어진 사용자 질의에 대한 의미론적 유사성을 계산하기 위해 지식 베이스의 조밀한 벡터 표현을 만드는 것입니다.\n",
    "이 노트북에서는 SentenceTransformers와 `all-MiniLM-L6-v2`를 사용할 예정입니다.\n",
    "해당 모델은 오픈소스 모델이며 로컬에서 실행될 수 있을 정도로 작아 incubation program이 종료된 후에도 사용 가능합니다.\n",
    "벡터 데이터베이스란 기존에 저희가 사용하던 DB와 비슷하나 벡터 인덱싱과 색인에 강점이 있습니다.  \n",
    "벡터라는 의미가 어려우시다면, 쉽게말해 단어와 단어간 비교할 때, 해당 단어 그 자체가 아니라, 단어의 의미를 활용하기 위해 딥러닝 모델을 활용하여 해당 단어(혹은 문장)의 의미론적 값을 의미한다고 생각하시면 되겠습니다.\n",
    "\n",
    "### 데이터셋\n",
    "세션에서 사용할 데이터셋은 위키(NQ open)피디아 데이터셋 중 오픈된 데이터셋의 일부를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871eb3d",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "Given that we are leveraging a locally-hosted embedding model, data ingestion and querying speeds can be slow.\n",
    "\n",
    "### Cookbook Structure\n",
    "1. Set-up dependencies\n",
    "2. Index knowledge base <br>\n",
    "3. Generate a retrieval-augmented response <br>\n",
    "4. Evaluate RAG performance on your data <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df2022",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "**이 행사에 사용된 The IBM GenAI Python library 는 현재 개발이 진행중이며 향후에 method나 class가 변경될 수 있습니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa972b",
   "metadata": {},
   "source": [
    "# 1. 패키지 설치 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae50a6",
   "metadata": {},
   "source": [
    "### 1.1 기존 패키지에서 추가적으로 설치를 해주어야 하는 부분이 있어 패키지를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d4db7d-2a2c-40c1-82dd-e829d3cd7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: rouge in c:\\users\\junyaupkim\\desktop\\finalize\\exp\\watsonx-incubation-program-korea\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\junyaupkim\\desktop\\finalize\\exp\\watsonx-incubation-program-korea\\.venv\\lib\\site-packages (from rouge) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "975528f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:05:28.892803Z",
     "start_time": "2023-06-23T05:05:26.136320Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "from typing import Optional, Any, Iterable, List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except ImportError:\n",
    "    raise ImportError(\"Could not import sentence_transformers: Please install sentence-transformers package.\")\n",
    "    \n",
    "try:\n",
    "    import chromadb\n",
    "    from chromadb.api.types import EmbeddingFunction\n",
    "except ImportError:\n",
    "    raise ImportError(\"Could not import chromdb: Please install chromadb package.\")\n",
    "    \n",
    "from typing import Dict, Optional, List\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57832b9",
   "metadata": {},
   "source": [
    "### 1.3. Load credentials for `ibm-watson-machine-learning`\n",
    "\n",
    "Your `.env` file needs to have the following lines without spaces around `=`. Set its path correctly in the below `get_wml_creds()` function.\n",
    "\n",
    "```\n",
    "API_KEY=<your-api_key>\n",
    "IBM_CLOUD_URL=<your-url>\n",
    "PROJECT_ID=<your-project_id>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a839010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:07:05.048160Z",
     "start_time": "2023-06-23T05:07:05.038242Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wml_creds():\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"API_KEY\", None)\n",
    "    ibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", None)\n",
    "    project_id = os.getenv(\"PROJECT_ID\", None)\n",
    "    if api_key is None or ibm_cloud_url is None or project_id is None:\n",
    "        print(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\n",
    "    else:\n",
    "        creds = {\n",
    "            \"url\": ibm_cloud_url,\n",
    "            \"apikey\": api_key \n",
    "        }\n",
    "    return project_id, creds\n",
    "\n",
    "\n",
    "project_id, creds = get_wml_creds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a1a9c",
   "metadata": {},
   "source": [
    "# 2. Index knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541d9f0",
   "metadata": {},
   "source": [
    "### 2.1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12816fda",
   "metadata": {},
   "source": [
    "실행하고 있는 경로에 다음 파일을 다운로드 받아 압축을 풀어줍니다(https://ibm.box.com/s/8fr8kw30rvpmzjaluvxeq007c7gwcgrg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2612737f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:05:51.749249Z",
     "start_time": "2023-06-23T05:05:51.732170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected dataset: LongNQ\n"
     ]
    }
   ],
   "source": [
    "datasets = ['LongNQ', 'nq910']\n",
    "dataset = datasets[0]    # The current dataset to use\n",
    "data_root = \"data\"\n",
    "data_dir = os.path.join(data_root, dataset)\n",
    "max_docs = -1\n",
    "print(\"Selected dataset:\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f14a4cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:05:57.530665Z",
     "start_time": "2023-06-23T05:05:55.901120Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_v1(data_dir, data_root):\n",
    "    passages = pd.read_csv(os.path.join(data_dir, \"passages.tsv\"), sep='\\t', header=0)\n",
    "    qas = pd.read_csv(os.path.join(data_dir, \"questions.tsv\"), sep='\\t', header=0).rename(columns={\"text\": \"question\"})\n",
    "    \n",
    "    # We only use 5000 examples.  Comment the lines below to use the full dataset.\n",
    "    passages = passages.head(5000)\n",
    "    qas = qas.head(5000)\n",
    "    \n",
    "    return passages, qas\n",
    "documents, questions = load_data_v1(data_dir, data_root)\n",
    "documents['indextext'] = documents['title'].astype(str) + \"\\n\" + documents['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d313c0",
   "metadata": {},
   "source": [
    "### 1.2. 임베딩 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f53ee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:06:01.792803Z",
     "start_time": "2023-06-23T05:06:01.403136Z"
    }
   },
   "outputs": [],
   "source": [
    "class MiniLML6V2EmbeddingFunction(EmbeddingFunction):\n",
    "    MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    def __call__(self, texts):\n",
    "        return MiniLML6V2EmbeddingFunction.MODEL.encode(texts).tolist()\n",
    "emb_func = MiniLML6V2EmbeddingFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa258ce6",
   "metadata": {},
   "source": [
    "### 2.3. Set up Chroma upsert\n",
    "중복 되는 키 값이 있다면 해당 value를 업데이트하고 그렇지 않다면(DB안에 없는 케이스라면) 해당 키 값에 대한 value를 추가하게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56139757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:06:07.012702Z",
     "start_time": "2023-06-23T05:06:07.010303Z"
    }
   },
   "outputs": [],
   "source": [
    "class ChromaWithUpsert:\n",
    "    def __init__(self, name,persist_directory, embedding_function,collection_metadata: Optional[Dict] = None,\n",
    "    ):\n",
    "        self._client = chromadb.PersistentClient(path=persist_directory)\n",
    "        self._embedding_function = embedding_function\n",
    "        self._persist_directory = persist_directory\n",
    "        self._name = name\n",
    "        self._collection = self._client.get_or_create_collection(\n",
    "            name=self._name,\n",
    "            embedding_function=self._embedding_function\n",
    "            if self._embedding_function is not None\n",
    "            else None,\n",
    "            metadata=collection_metadata,\n",
    "        )\n",
    "\n",
    "    def upsert_texts(\n",
    "        self,\n",
    "        texts: Iterable[str],\n",
    "        metadata: Optional[List[dict]] = None,\n",
    "        ids: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
    "        Args:\n",
    "            :param texts (Iterable[str]): Texts to add to the vectorstore.\n",
    "            :param metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
    "            :param ids (Optional[List[str]], optional): Optional list of IDs.\n",
    "            :param metadata: Optional[List[dict]] - optional metadata (such as title, etc.)\n",
    "        Returns:\n",
    "            List[str]: List of IDs of the added texts.\n",
    "        \"\"\"\n",
    "        # TODO: Handle the case where the user doesn't provide ids on the Collection\n",
    "        if ids is None:\n",
    "            import uuid\n",
    "            ids = [str(uuid.uuid1()) for _ in texts]\n",
    "        embeddings = None\n",
    "        self._collection.upsert(\n",
    "            metadatas=metadata, documents=texts, ids=ids\n",
    "        )\n",
    "        return ids\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self._collection.count()==0\n",
    "\n",
    "    def query(self, query_texts:str, n_results:int=5):\n",
    "        \"\"\"\n",
    "        Returns the closests vector to the question vector\n",
    "        :param query_texts: the question\n",
    "        :param n_results: number of results to generate\n",
    "        :return: the closest result to the given question\n",
    "        \"\"\"\n",
    "        return self._collection.query(query_texts=query_texts, n_results=n_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8a329",
   "metadata": {},
   "source": [
    "###  2.4 Embed and index documents with Chroma\n",
    "ChromaDB를 활용한 임베딩과 인덱싱에 개인 노트북에 따라 시간이 다르게 걸릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130ed17f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:06:09.781614Z",
     "start_time": "2023-06-23T05:06:09.057648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8min 57s\n",
      "Wall time: 5min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chroma = ChromaWithUpsert(\n",
    "    name=f\"{dataset}_minilm6v2\",\n",
    "    embedding_function=emb_func,  # you can have something here using /embed endpoint\n",
    "    persist_directory=data_dir,\n",
    ")\n",
    "if chroma.is_empty():\n",
    "    _ = chroma.upsert_texts(\n",
    "        texts=documents.indextext.tolist(),\n",
    "        # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "        metadata=[{'title': title, 'id': id}\n",
    "                  for (title,id) in\n",
    "                  zip(documents.title, documents.id)],  # filter on these!\n",
    "        ids=[str(i) for i in documents.id],  # unique for each doc\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad9d3e",
   "metadata": {},
   "source": [
    "# 3. Generate a retrieval-augmented response to a question "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd72043",
   "metadata": {},
   "source": [
    "### 3.1. Instantiate `watsonx` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86fa76de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:07:26.944301Z",
     "start_time": "2023-06-23T05:07:26.934952Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        GenParams.DECODING_METHOD: \"greedy\",\n",
    "        GenParams.MIN_NEW_TOKENS: 1,\n",
    "        GenParams.MAX_NEW_TOKENS: 100,\n",
    "        GenParams.TEMPERATURE: 0,\n",
    "    }\n",
    "model = Model(model_id='meta-llama/llama-2-70b-chat', params=params, credentials=creds, project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056acd65",
   "metadata": {},
   "source": [
    "### 3.2. Select a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "326bc593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:08:48.075507Z",
     "start_time": "2023-06-23T05:08:48.073575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the tax rate for lottery winnings in california?\n"
     ]
    }
   ],
   "source": [
    "question_index = 65\n",
    "question_text = questions.question[question_index].strip(\"?\") + \"?\"\n",
    "print(question_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9fdb71",
   "metadata": {},
   "source": [
    "### 3.3. Retrieve relevant context\n",
    "질문을 임베딩으로 변환할 Chroma로 보내고 지정된 수의 일치하는 구절에 대해 유사성 검색을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad2e4e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:08:50.401567Z",
     "start_time": "2023-06-23T05:08:50.324748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "Paragraph index :  4172\n",
      "Paragraph :  California State Lottery\n",
      "Assembly Member Van Tran 's Assembly Bill 1251 , modifying California Government Code section 8880.321 to allow for a one - year claim period for a Mega Millions jackpot prize . This is the only prize in California that has a one - year claim period . All other prizes have the 180 - day claim period . This legislation affected Mega Millions drawings after July 5 , 2008 . All prizes for Fantasy 5 , Daily Derby , Daily 3 , Daily 4 , and non-jackpot SuperLotto Plus , Mega Millions , and Powerball prizes , are paid out in one payment , less 25 % or 33 % ( depending upon the winner 's tax documentation ) Federal withholding if the prize is over $5,000 . Merchandise prizes over $5,000 are subject to 33 % Federal withholding . Scratchers tickets are generally one - payment prizes ; however , some games have annuity options for payments each year , or per week . California does not tax California Lottery winnings , however it taxes lottery winnings from other jurisdictions . For SuperLotto Plus and Mega Millions jackpots , the player may choose a single cash payout for a floating percentage of the jackpot , or an annuity . The SuperLotto Plus , Mega Millions , and Powerball payment schedule are on a graduated basis over 30 annual payments . Until 2005 , when California joined Mega Millions , the payment choice on SuperLotto Plus had to be made\n",
      "Distance :  0.579059362411499\n",
      "=========\n",
      "Paragraph index :  4827\n",
      "Paragraph :  California State Lottery\n",
      "Assembly Member Van Tran 's Assembly Bill 1251 , modifying California Government Code section 8880.321 to allow for a one - year claim period for a Mega Millions jackpot prize . This is the only prize in California that has a one - year claim period . All other prizes have the 180 - day claim period . This legislation affected Mega Millions drawings after July 5 , 2008 . All prizes for Fantasy 5 , Daily Derby , Daily 3 , Daily 4 , and non-jackpot SuperLotto Plus , Mega Millions , and Powerball prizes , are paid out in one payment , less 25 % or 33 % ( depending upon the winner 's tax documentation ) Federal withholding if the prize is over $5,000 . Merchandise prizes over $5,000 are subject to 33 % Federal withholding . Scratchers tickets are generally one - payment prizes ; however , some games have annuity options for payments each year , or per week . California does not tax California Lottery winnings , however it taxes lottery winnings from other jurisdictions . For SuperLotto Plus and Mega Millions jackpots , the player may choose a single cash payout for a floating percentage of the jackpot , or an annuity . The SuperLotto Plus , Mega Millions , and Powerball payment schedule are on a graduated basis over 30 annual payments . Until 2005 , when California joined Mega Millions , the payment choice on SuperLotto Plus had to be made\n",
      "Distance :  0.579059362411499\n",
      "=========\n",
      "Paragraph index :  4171\n",
      "Paragraph :  California State Lottery\n",
      "than other lottery games , but there are better odds ( averaging 1 : 5 ) . There are dozens of Scratchers games on sale at any time , and the selection of games changes frequently . Winners must be claimed within 180 days of the announced end - of - game date . Scratchers range in price from $1 to $10 . A $20 scratcher , `` $5 Million Jackpot '' , was introduced September 25 , 2013 . To commemorate the Lottery 's 30th anniversary , on August 24th , 2015 , a $30 Scratcher `` California Lottery 30th Anniversary '' was launched . For each prize of less than $600 , players may collect from either a Lottery retailer or the Lottery itself . Prizes of $600 or more must be collected from the Lottery , via claim form . Almost all prizes must be claimed within 180 days of the draw or the announced end of the game . If the 180th day is a weekend or holiday , the final claim date is extended to the next business day . Any unclaimed prize money is transferred to the education fund in addition to the minimum 34 % that the Lottery is already obligated to transfer from income . Because many of the 44 Mega Millions participants have a one - year claim period , the California legislature changed the language in the Lottery Act . On April 23 , 2008 , Gov. Arnold Schwarzenegger signed\n",
      "Distance :  0.6069095730781555\n",
      "=========\n",
      "Paragraph index :  4826\n",
      "Paragraph :  California State Lottery\n",
      "than other lottery games , but there are better odds ( averaging 1 : 5 ) . There are dozens of Scratchers games on sale at any time , and the selection of games changes frequently . Winners must be claimed within 180 days of the announced end - of - game date . Scratchers range in price from $1 to $10 . A $20 scratcher , `` $5 Million Jackpot '' , was introduced September 25 , 2013 . To commemorate the Lottery 's 30th anniversary , on August 24th , 2015 , a $30 Scratcher `` California Lottery 30th Anniversary '' was launched . For each prize of less than $600 , players may collect from either a Lottery retailer or the Lottery itself . Prizes of $600 or more must be collected from the Lottery , via claim form . Almost all prizes must be claimed within 180 days of the draw or the announced end of the game . If the 180th day is a weekend or holiday , the final claim date is extended to the next business day . Any unclaimed prize money is transferred to the education fund in addition to the minimum 34 % that the Lottery is already obligated to transfer from income . Because many of the 44 Mega Millions participants have a one - year claim period , the California legislature changed the language in the Lottery Act . On April 23 , 2008 , Gov. Arnold Schwarzenegger signed\n",
      "Distance :  0.6069095730781555\n",
      "=========\n",
      "Paragraph index :  4811\n",
      "Paragraph :  California State Lottery\n",
      "California State Lottery The California State Lottery logo as of 2008 Formation November 6 , 1984 Type Lottery System Headquarters Sacramento , California , United States Website www.calottery.com The California State Lottery logo as of 2008 Formation November 6 , 1984 Type Lottery System Headquarters Sacramento , California , United States Website www.calottery.com The California State Lottery , also known as the California Lottery , began on November 6 , 1984 , after California voters passed Proposition 37 , the California State Lottery Act of 1984 , to authorize the creation of a lottery . The first tickets were purchased on October 3 , 1985 . The California State Lottery Act of 1984 was intended to provide more money to schools without imposing extra taxes . Accordingly , the Lottery was required to provide at least 34 % of its revenues to public education , supplementing ( not replacing ) other funds provided by California . Another 50 % of its revenues must be paid to the public in the form of prizes , making a mandated minimum of 84 % of all funds that must be given back to the public in the form of prizes or funds for public education . The remainder , a maximum of 16 % , was to be spent on administration , such as salaries and running the games . On April 8 , 2010 , Governor Schwarzenegger signed into law Bill 142 ( Hayashi , D - Hayward ) . Amending the\n",
      "Distance :  0.6683824062347412\n"
     ]
    }
   ],
   "source": [
    "relevant_chunks = chroma.query(\n",
    "    query_texts=[question_text],\n",
    "    n_results=5,\n",
    ")\n",
    "for i, chunk in enumerate(relevant_chunks['documents'][0]):\n",
    "    print(\"=========\")\n",
    "    print(\"Paragraph index : \", relevant_chunks['ids'][0][i])\n",
    "    print(\"Paragraph : \", chunk)\n",
    "    print(\"Distance : \", relevant_chunks['distances'][0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02484a",
   "metadata": {},
   "source": [
    "### 3.4. Feed the context and the question to `watsonx` model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb5669",
   "metadata": {},
   "source": [
    "`make_prompt`는 유저의 질문과 VectorDB에서 추출된 문서 청크를 활용하여 프롬프트를 생성하는 함수입니다. 프롬프트를 변경하면 때로는 훨씬 더 적절한 답변이 나올 수 있습니다(또는 품질이 크게 저하될 수 있습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "304c54fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:08:52.935954Z",
     "start_time": "2023-06-23T05:08:52.932090Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_prompt(context, question_text):\n",
    "    return (f\"{context}\\n\\nPlease answer a question using this \"\n",
    "          + f\"text. \"\n",
    "          + f\"If the question is unanswerable, say \\\"unanswerable\\\".\"\n",
    "          + f\"Question: {question_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ac534c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:08:54.181653Z",
     "start_time": "2023-06-23T05:08:54.171754Z"
    }
   },
   "outputs": [],
   "source": [
    "context = \"\\n\\n\\n\".join(relevant_chunks[\"documents\"][0])\n",
    "prompt = make_prompt(context, question_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754300cc",
   "metadata": {},
   "source": [
    "Generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e32e1cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:09:03.685451Z",
     "start_time": "2023-06-23T05:08:56.884170Z"
    }
   },
   "outputs": [],
   "source": [
    "response = model.generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9d5c81c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:09:03.693101Z",
     "start_time": "2023-06-23T05:09:03.683809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question =  what is the tax rate for lottery winnings in california?\n",
      "Answer =  \n",
      "\n",
      "Answer: California does not tax California Lottery winnings, however it taxes lottery winnings from other jurisdictions.\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  All prizes for Fantasy 5, Daily Derby, Daily 3, Daily 4, and non-jackpot SuperLotto Plus, Mega Millions, and Powerball prizes, are paid out in one payment, less 25 % or 33 % (depending upon the winner 's tax documentation) Federal Withholding if the prize is over $5,000. California does not tax California Lottery winnings, however it taxes lottery winnings from other jurisdictions.\n"
     ]
    }
   ],
   "source": [
    "print(\"Question = \", question_text)\n",
    "print(\"Answer = \", response)\n",
    "print(\"Expected Answer(s) (may not be appear with exact wording in the dataset) = \", questions.answers[question_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8df92",
   "metadata": {},
   "source": [
    "## 4. RAG 성능 평가 방법\n",
    "Evaluating the performance of your Generative AI system is critical to ensuring happy end users.  However evaluation also requires having a test dataset.  In this case, the top passages that shoudl be return for each question.\n",
    "\n",
    "Note that we want to evaluate the performance of both (1) the embedding function plus (2) how well the GenAI model summarizes the results.\n",
    "\n",
    "So our test set must contain:\n",
    "1. The indexes of the passage(s) that contain the answer - i.e. the goldstandard passages (if the question is answerable by the knowledge base)\n",
    "2. The question's gold standard answer (this can be short or long-form)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f441d1e",
   "metadata": {},
   "source": [
    "### 4.1. Evaluate the retrieval quality\n",
    "Were the correct passages returned via the similarity search functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17ccec6",
   "metadata": {},
   "source": [
    "There are many ways to compute retrieval quality, namely how the information contained in the documents that are relevant to the question being asked. We're focusing here on success at given number of returns  (aka recall at given levels), which is to say, given a fixed number of documents returned (e.g., 1, 3, 5), is the question's answer contained in them. The scores increase with the recall level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ba37f5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:10:40.354510Z",
     "start_time": "2023-06-23T05:10:40.321992Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_score(questions, answers, ranks=[1, 3, 5, 10], use_rouge=False, rouge_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Computes the success at different levels of recall, given the goldstandard passage indexes per query.\n",
    "    It computes two scores:\n",
    "       * Success at rank_i, defined as sum_q 1_{top i answers for question q contains a goldstandard passage} / #questions\n",
    "       * Lenient success at rank i, defined as\n",
    "                sum_q 1_{ one in the documents in top i for question q contains a goldstandard answer) / #questions\n",
    "    Note that a document that contains the actual textual answer does not necesarily answer the question, hence it's a\n",
    "    more lenient evaluation. Any goldstandard passage will contain a goldstandard answer text, by definition.\n",
    "    Args:\n",
    "        :param questions: List[Dict['id': AnyStr, 'text': AnyStr, 'relevant': AnyStr, 'answers': AnyStr]]\n",
    "           - the input queries. Each query is a dictionary with the keys 'id','text', 'relevant', 'answers'.\n",
    "        :param input_passages: List[Dict['id': AnyStr, 'text': AnyStr', 'title': AnyStr]]\n",
    "           - the input passages. These are used to create a reverse-index list for the passages (so we can get the\n",
    "             text for a given passage ID)\n",
    "        :param answers: List[List[AnyStr]]\n",
    "           - the retrieved passages IDs for each query\n",
    "        :param ranks: List[int]\n",
    "           - the ranks at which to compute success\n",
    "        :param use_rouge: Boolean\n",
    "           - turns on the use of rouge as a scorer\n",
    "        :param rouge_threshold: float, default=0.7\n",
    "           - defines the minimum rouge-l/r score to accept the answer as a match,\n",
    "    Returns:\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # if \"relevant\" not in input_queries[0] or input_queries[0]['relevant'] is None:\n",
    "    #     print(\"The input question file does not contain answers. Please fix that and restart.\")\n",
    "    #     sys.exit(12)\n",
    "\n",
    "    scores = {r: 0 for r in ranks}\n",
    "    lscores = {r: 0 for r in ranks}\n",
    "\n",
    "    gt = {}\n",
    "    for q_relevant, q_qid in zip(questions.relevant, questions.qid):\n",
    "        if isinstance(q_relevant, str):\n",
    "            rel = [int(i) for i in q_relevant.split(\",\")]\n",
    "        else:\n",
    "            rel = [q_relevant]\n",
    "        gt[q_qid] = rel\n",
    "\n",
    "    def update_scores(ranks, rnk, scores):\n",
    "        j = 0\n",
    "        while j < len(ranks) and ranks[j] < rnk:\n",
    "            j += 1\n",
    "        for k in ranks[j:]:\n",
    "            scores[k] += 1\n",
    "\n",
    "    scorer = None\n",
    "    if use_rouge:\n",
    "        from rouge import Rouge\n",
    "        scorer = Rouge()\n",
    "\n",
    "    num_eval_questions = 0\n",
    "\n",
    "    for qi, (qid, q_answers) in enumerate(zip(questions.qid, questions.answers)):\n",
    "        tmp_scores = {r: 0 for r in ranks}\n",
    "\n",
    "        text_answers = str(q_answers).split(\"::\")\n",
    "        if \"-\" in text_answers:\n",
    "            # The question does not have answers, skip it for retrieval score purposes.\n",
    "            continue\n",
    "        num_eval_questions += 1\n",
    "        # Compute scores based on the goldstandard annotation\n",
    "        for ai, ans in enumerate(answers[qi]):\n",
    "            if int(ans['id']) in gt[qid]:  # Great, we found a match.\n",
    "                update_scores(ranks, ai + 1, tmp_scores)\n",
    "                break\n",
    "\n",
    "        # Compute score on approximate match - either answer inclusion in the text or\n",
    "        # minimum rouge score alignment.\n",
    "        tmp_lscores = tmp_scores.copy()  # making sure we're actually lenient\n",
    "        #inputq = questions[qi]\n",
    "        for ai, ans in enumerate(answers[qi]):\n",
    "            txt = ans['text'].lower()\n",
    "            found = False\n",
    "            for text_answer in text_answers:\n",
    "                if use_rouge:\n",
    "                    score = scorer.get_scores(text_answer.lower(), txt)\n",
    "                    if max(score[0]['rouge-l']['r'], score[0]['rouge-l']['p']) > rouge_threshold:\n",
    "                        update_scores(ranks, ai + 1, tmp_lscores)\n",
    "                        break\n",
    "                else:\n",
    "                    if not isinstance(text_answer, str):\n",
    "                        print(f\"Error on text_answer {text_answer}, question {qi}, answer {ai}-{ans}\")\n",
    "                    if txt.find(text_answer.lower()) >= 1:\n",
    "                        update_scores(ranks, ai + 1, tmp_lscores)\n",
    "                        break\n",
    "\n",
    "        for r in ranks:\n",
    "            scores[r] += int(tmp_scores[r] >= 1)\n",
    "            lscores[r] += int(tmp_lscores[r] >= 1)\n",
    "\n",
    "    res = {\"num_ranked_queries\": num_eval_questions,\n",
    "           \"num_judged_queries\": num_eval_questions,\n",
    "           \"success\":\n",
    "               {r: int(1000 * scores[r] / num_eval_questions) / 1000.0 for r in ranks},\n",
    "           \"lenient_success\":\n",
    "               {r: int(1000 * lscores[r] / num_eval_questions) / 1000.0 for r in ranks},\n",
    "           \"counts\": {r: scores[r] for r in ranks},\n",
    "           'lcounts': {r: lscores[r] for r in ranks}\n",
    "           }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d3cec",
   "metadata": {},
   "source": [
    "### Compute the retrieval score over all the documents\n",
    "Can take up to a minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "191373f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:10:48.065035Z",
     "start_time": "2023-06-23T05:10:42.227465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_ranked_queries': 300, 'num_judged_queries': 300, 'success': {1: 0.08, 3: 0.143, 5: 0.163}, 'lenient_success': {1: 0.086, 3: 0.15, 5: 0.17}, 'counts': {1: 24, 3: 43, 5: 49}, 'lcounts': {1: 26, 3: 45, 5: 51}}\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "retrieved_docs = []\n",
    "for q in questions.question:\n",
    "    answers = chroma.query(query_texts=q, n_results=k)\n",
    "\n",
    "    retrieved_docs.append([{'id': id, 'text': text}\n",
    "                           for (id, text) in zip(answers['ids'][0], answers['documents'][0])])\n",
    "\n",
    "res = compute_score(questions, retrieved_docs,\n",
    "                    ranks=[1, 3, 5], use_rouge=(data_dir == 'docs_and_qs'))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e591ba75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:10:52.951489Z",
     "start_time": "2023-06-23T05:10:52.736414Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot(res):\n",
    "    fig, ax = plt.subplots()\n",
    "    scores = res['success'].values()\n",
    "    keys = [f'R@{i}' for i in res['success'].keys()]\n",
    "    x_pos = np.arange(len(keys))\n",
    "    ax.bar(x_pos, scores, align='center', alpha=0.5)\n",
    "    ax.set_ylabel('Success Rate')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(keys)\n",
    "    ax.set_title('Success rates at different recall rates.')\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "    # Save the figure and show\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bar_plot.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "097ecacb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:10:53.857005Z",
     "start_time": "2023-06-23T05:10:53.434507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e8be5-0399-43ef-9d97-b148c7a1479b",
   "metadata": {},
   "source": [
    "## 심화 세션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8438b5c1",
   "metadata": {},
   "source": [
    "### 4.2. Evaluate quality of generated responses\n",
    "I.e. how well did the GenAI model summarize and extract the correct answer to the user's question from the passages returned by the similarity function.  Obviously if the returned passages were invalid, then performance at this phase would suffer too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989f4832",
   "metadata": {},
   "source": [
    "Automatically evaluating the quality of answers is difficult, as many factors come into play, such as fluency, helpfulness, coverage, etc. One simplified way of computing this quality is using the ROUGE metric, in particular ROUGE-L. To compute this metric, for every answer returned for a question, we measure the maximum subsequence of words between the system answer and the gold-standard answer. Given this sequence, we can compute the precision of the given answer as the length (all lengths are in words) of this sequence divided by the length of the system answer and the recall as the length of the longest common subsequence divided by the length the gold-standard answer.\n",
    "$$ P_{ROUGE-L} = \\frac{|lcs(system,gold)|}{|system|} \\\\ R_{ROUGE_L} = \\frac{|lcs(system,gold|}{|gold|} $$\n",
    "\n",
    "where $lcs(system, gold)$ is the longest commong subsequence between $system$ and $gold$.\n",
    "\n",
    "ROUGE was devised in the NLP community to evaluate summarization, and is commonly used to also evaluate abstractive question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bcceec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:10:58.494098Z",
     "start_time": "2023-06-23T05:10:58.490061Z"
    }
   },
   "outputs": [],
   "source": [
    "def score_answers(_answers, _reference, score_type=\"rouge-l\", val=\"r\", use_rouge=True):\n",
    "    \"\"\"\n",
    "    Compute the score of a set of answers, given a set of references, using Rouge score.\n",
    "    :param answers: Union[List[str], str]\n",
    "       - the returned answer/answers.\n",
    "    :param reference:\n",
    "        - the reference answers, in a string. Answers are separated by ':::'\n",
    "    :param use_rouge: Boolean\n",
    "        - if true, then use rouge for scoring, otherwise use substring.\n",
    "    :return:\n",
    "       - The maximum rouge-L score of the cartesian product of answers/references\n",
    "    \"\"\"\n",
    "    if isinstance(_answers, str):\n",
    "        _answers = [_answers]\n",
    "    _references = _reference.lower().split(\"::\")\n",
    "    max_score = -1\n",
    "    scorer = Rouge()\n",
    "    closest_ref = \"\"\n",
    "    for ref in _references:\n",
    "        for _answer in _answers:\n",
    "            if use_rouge:\n",
    "                scores = scorer.get_scores(_answer.lower(), ref)\n",
    "                score = scores[0][score_type][val]\n",
    "            else:\n",
    "                score = int(ref.find(_answer.lower()) >= 0)\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                closest_ref = ref\n",
    "\n",
    "    return max_score, closest_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44600561",
   "metadata": {},
   "source": [
    "Compute the score for the previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c0e9fdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:11:01.751553Z",
     "start_time": "2023-06-23T05:11:01.735763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question =  what is the tax rate for lottery winnings in california?\n",
      "Answer =  \n",
      "\n",
      "Answer: California does not tax California Lottery winnings, however it taxes lottery winnings from other jurisdictions.\n",
      "Closest reference: \"all prizes for fantasy 5, daily derby, daily 3, daily 4, and non-jackpot superlotto plus, mega millions, and powerball prizes, are paid out in one payment, less 25 % or 33 % (depending upon the winner 's tax documentation) federal withholding if the prize is over $5,000. california does not tax california lottery winnings, however it taxes lottery winnings from other jurisdictions.\"\n",
      "Recall:\t\t24.07%\n",
      "Precision:\t92.86%\n"
     ]
    }
   ],
   "source": [
    "print(\"Question = \", question_text)\n",
    "print(\"Answer = \", response)\n",
    "score, closest_ref = score_answers(response, questions.answers[question_index], val='r')\n",
    "print(f\"Closest reference: \\\"{closest_ref}\\\"\")\n",
    "print(f\"Recall:\\t\\t{100*score:5.2f}%\")\n",
    "score, _ = score_answers(response, questions.answers[question_index], val='p')\n",
    "print(f\"Precision:\\t{100*score:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97f9e8",
   "metadata": {},
   "source": [
    "#### Compute (Rouge-based) precision and recall for the entire collection.\n",
    "\n",
    "It takes about 1-2 seconds per question. For a corpus of ~1000 questions, this take can take up to 30min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84e5093a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:11:09.652689Z",
     "start_time": "2023-06-23T05:11:09.636571Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_answerable(relevant):\n",
    "    return \"-1\" in relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4c8ba27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:13:38.229938Z",
     "start_time": "2023-06-23T05:11:10.273038Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [02:54<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "source": [
    "rscore = 0\n",
    "pscore = 0\n",
    "import tqdm\n",
    "num_eval_questions = 50\n",
    "eval_questions = questions[:num_eval_questions]\n",
    "count = {\"11\": 0, \"10\": 0, \"01\": 0, \"00\": 0}\n",
    "seq = []\n",
    "for (question_text, answers, relevant) in tqdm.tqdm(zip(eval_questions.question, eval_questions.answers, eval_questions.relevant), total=len(eval_questions)):\n",
    "    # ans = qa(question.question)\n",
    "    relevant_chunks = chroma.query(\n",
    "        query_texts=[question_text],\n",
    "        n_results=5,\n",
    "    )\n",
    "    context = \"\\n\\n\\n\".join(relevant_chunks[\"documents\"][0])\n",
    "    prompt = make_prompt(context, question_text)\n",
    "    ans = model.generate_text(prompt)\n",
    "    q_answerable = is_answerable(relevant)\n",
    "    if ans == \"unanswerable\":\n",
    "        res = \"10\" if q_answerable else \"00\"\n",
    "        count [res] += 1\n",
    "        if not q_answerable:\n",
    "            rscore += 1\n",
    "            pscore += 1\n",
    "    else:\n",
    "        res = \"11\" if q_answerable else \"10\"\n",
    "        count[res] += 1\n",
    "        if q_answerable:\n",
    "            qrscore, _ = score_answers(ans, answers, val='r')\n",
    "            rscore += qrscore\n",
    "            qpscore, _ = score_answers(ans, answers, val='p')\n",
    "            pscore += qpscore\n",
    "    seq.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d367a0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:23:29.963594Z",
     "start_time": "2023-06-23T05:23:29.960973Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "def displayHTMLTables(*tables):\n",
    "    def htmlTable(table):\n",
    "        return '<table border=\"2\"><tr>{}</tr></table>'.format(\n",
    "                    '</tr><tr>'.join(\n",
    "                        '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in table)\n",
    "                )\n",
    "\n",
    "    display(HTML('<table><tr><td>{}</td></tr></table>'.format(\n",
    "                \"</td><td>\".join(htmlTable(table) for table in tables))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f266aaa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:30:09.511761Z",
     "start_time": "2023-06-23T05:30:09.503861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><table border=\"2\"><tr><td></td><td>Overall</td><td>Answerable questions</td></tr><tr><td>Precision</td><td> 0.05</td><td> 0.05</td></tr><tr><td>Recall</td><td> 0.05</td><td> 3.76</td></tr></table></td><td><table border=\"2\"><tr></tr></table></td><td><table border=\"2\"><tr></tr></table></td><td><table border=\"2\"><tr><td>Gold/System</td><td>No Answer</td><td>Answered</td></tr><tr><td>No Answer</td><td>0</td><td>0</td></tr><tr><td>With Answer</td><td>28</td><td>22</td></tr></table></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = [['', 'Overall', 'Answerable questions'],\n",
    "       ['Precision', f\"{100*pscore/len(eval_questions):5.2f}\", f\"{100*(pscore-count['00'])/(count['10']+count['11']):5.2f}\"],\n",
    "       ['Recall',    f'{100*pscore/len(eval_questions):5.2f}', f\"{188*(rscore-count['00'])/(count['10']+count['11']):5.2f}\"],\n",
    "       ]\n",
    "counts = [['Gold/System', 'No Answer', 'Answered'],\n",
    "        ['No Answer', count[\"00\"], count[\"01\"]],\n",
    "        ['With Answer', count[\"10\"], count[\"11\"]]]#%% md\n",
    "\n",
    "displayHTMLTables(res, [], [], counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc5e35-5eaf-416c-a99c-62d9e3d325ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
