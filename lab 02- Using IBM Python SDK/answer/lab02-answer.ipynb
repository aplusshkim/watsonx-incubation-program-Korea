{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea23381-7302-423a-93b7-346e56f4af6b",
   "metadata": {},
   "source": [
    "## Prompt Lab Challenge Exercises Notebook\n",
    "\n",
    "프롬프트 랩 챌린지 연습 노트북에 오신 걸 환영합니다! 부트캠프 시리즈의 두 번째 실습입니다. 실습 1의 연습을 모두 완료했다면, 여기서의 대부분의 연습이 수월할 거에요.\n",
    "\n",
    "이 노트북은 연습은 프롬프트가 잘 작동했을 때 어떤 결과가 나와야 하는지 표시된 템플릿이에요.\n",
    "\n",
    "먼저 시작하기 전에, 이전 실습에서 말한대로 필요한 라이브러리가 설치된 Python 환경과 다음 내용이 담긴 .env 파일이 필요해요.\n",
    "\n",
    "+ IBM Cloud API 키  \n",
    "+ IBM Cloud 지역 URL (예: https://us-south.ml.cloud.ibm.com)  \n",
    "+ WatsonX 프로젝트에 연결된 프로젝트 ID (WML Python SDK에서 필요)  \n",
    "\n",
    "이 연습을 완료하는 데는 약 30~45분이 소요될 것으로 예상돼요. 편안하게 진행해 보세요!  \n",
    "\n",
    "행운을 빕니다. 답을 비교해보는 걸 잊지 마세요!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ab41f0-22ae-4da2-b599-efd291181593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 요약 , in Korean:, han-gul: 등이있다.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5491229c-49b9-4f2b-9837-691929b832a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config Watsonx.ai environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\", None)\n",
    "ibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", None)\n",
    "project_id = os.getenv(\"PROJECT_ID\", None)\n",
    "if api_key is None or ibm_cloud_url is None or project_id is None:\n",
    "    raise Exception(\"Ensure you copied the .env file that you created earlier into the same directory as this notebook\")\n",
    "else:\n",
    "    creds = {\n",
    "        \"url\": ibm_cloud_url,\n",
    "        \"apikey\": api_key \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7be8650-c7f5-4b54-939f-a582a84821c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_watsonxai(prompts,\n",
    "                    model_name=\"meta-llama/llama-2-70b-chat\",\n",
    "                    decoding_method=\"greedy\",\n",
    "                    max_new_tokens=100,\n",
    "                    min_new_tokens=30,\n",
    "                    temperature=1.0,\n",
    "                    repetition_penalty=1.0,\n",
    "                    stop_sequence=['\\n\\n']\n",
    "                    ):\n",
    "    '''\n",
    "   helper function for sending prompts and params to Watsonx.ai\n",
    "    \n",
    "    Args:  \n",
    "        prompts:list list of text prompts\n",
    "        decoding:str Watsonx.ai parameter \"sample\" or \"greedy\"\n",
    "        max_new_tok:int Watsonx.ai parameter for max new tokens/response returned\n",
    "        temperature:float Watsonx.ai parameter for temperature (range 0>2)\n",
    "        repetition_penalty:float Watsonx.ai parameter for repetition penalty (range 1.0 to 2.0)\n",
    "\n",
    "    Returns: None\n",
    "        prints response\n",
    "    '''\n",
    "\n",
    "    assert not any(map(lambda prompt: len(prompt) < 1, prompts)), \"make sure none of the prompts in the inputs prompts are empty\"\n",
    "\n",
    "    # Instantiate parameters for text generation\n",
    "    model_params = {\n",
    "        GenParams.DECODING_METHOD: decoding_method,\n",
    "        GenParams.MIN_NEW_TOKENS: min_new_tokens,\n",
    "        GenParams.MAX_NEW_TOKENS: max_new_tokens,\n",
    "        GenParams.RANDOM_SEED: 42,\n",
    "        GenParams.TEMPERATURE: temperature,\n",
    "        GenParams.REPETITION_PENALTY: repetition_penalty,\n",
    "    }\n",
    "    \n",
    "    # Instantiate a model proxy object to send your requests\n",
    "    model = Model(\n",
    "        model_id=model_name,\n",
    "        params=model_params,\n",
    "        credentials=creds,\n",
    "        project_id=project_id)\n",
    "\n",
    "\n",
    "    for prompt in prompts:\n",
    "        print(model.generate_text(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd435da-8c95-4c53-8a74-d71615e5501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAN_T5_XXL = 'google/flan-t5-xxl'\n",
    "FLAN_UL2 = 'google/flan-ul2'\n",
    "GPT_NEOX = 'eleutherai/gpt-neox-20b'\n",
    "GRANITE_13B_CHAT = 'ibm/granite-13b-chat-v1'\n",
    "GRANITE_13B_INSTRUCT = 'ibm/granite-13b-instruct-v1'\n",
    "LLAMA_2_70B_CHAT = 'meta-llama/llama-2-70b-chat'\n",
    "MPT_7B_INSTRUCT2 = 'ibm/mpt-7b-instruct2'\n",
    "MT0_XXL = 'bigscience/mt0-xxl'\n",
    "STARCODER = 'bigcode/starcoder'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20288337-7359-4618-a1b3-e6ea23a3fe9c",
   "metadata": {},
   "source": [
    "#### Q1) 리뷰의 감정을 반환하기 위한 프롬프트를 작성하세요.\n",
    "Target sentiment = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64373552-ec4d-467c-8d4a-fb680d9829ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Review for Questions  1 - 5\n",
    "review = \"\"\"침실에 좋은 램프가 필요해서 이 제품을 선택했는데, 추가 저장 공간이 있고 가격도 너무 싸요. \n",
    "빨리 받았습니다. 우리 램프의 스트링이 운송 중에 끊겼는데, 회사에서 기꺼이 새로운 것을 보내주었어요. \n",
    "또한 몇 일 안에 도착했습니다. 조립하기 쉬웠어요. \n",
    "부품이 빠져 있어 고객 지원팀에 연락했고, 빠르게 보내주었습니다! \n",
    "Lumina는 고객과 제품에 관심을 가지고 있는 회사로 보입니다!!\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61172de-dca0-4a29-95b1-15489447fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "답: Positive\n"
     ]
    }
   ],
   "source": [
    "#Q1 Code - enter prompt and parameters in this cell\n",
    "prompt = f\"\"\"\n",
    "{review}\n",
    "\n",
    "위의 문장의 감정을 positive 또는 negative로  분류해줘. \n",
    "\"\"\"\n",
    "#영어를 사용하지말고 한국어를 사용하세요 #Complete your prompt here \n",
    "\n",
    "response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_2_70B_CHAT, decoding_method=\"greedy\", max_new_tokens=9,\n",
    "                              min_new_tokens=1, temperature=0, repetition_penalty=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837ee21-179c-4985-b0af-a2002c167dcb",
   "metadata": {},
   "source": [
    "#### Q2) 리뷰어가 표현한 감정을 추출하고, 답변을 쉼표로 구분된 목록으로 반환하세요.\n",
    "대상 감정 = 만족, 제품 좋음, 회사좋음 , 배송좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbf2115-61a6-432b-b174-03027d65a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "답: 만족, 제품 좋음, 회사좋음, 배송좋음\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = f''' \n",
    "\"\"\"{review}\"\"\"\n",
    "\n",
    "삼중따옴표로 구성된 위의 문장의 감정을 만족, 불만족, 분노, 슬픔, 행복, 실망, 제품 좋음, 회사좋음, 배송좋음 중에서 추출해줘.\n",
    "'''\n",
    "#영어를 사용하지말고 한국어를 사용하세요 #Complete your prompt here \n",
    "\n",
    "response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_2_70B_CHAT,  decoding_method=\"greedy\", max_new_tokens=100,\n",
    "                              min_new_tokens=1, temperature=0, repetition_penalty=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91ccad-bda3-41a8-97ac-97cae92e44e6",
   "metadata": {},
   "source": [
    "#### Q3) 리뷰어가 분노를 표현하고 있는가요? \"예\" 또는 \"아니오\"로 답하세요. – 분노를 포함한 여러 예제를 사용하여 양쪽 경우에 모두 작동하는지 확인하세요.\n",
    "Target answer = 아니요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e738c6-a54c-4b44-9b6a-f6d88ab6d5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "답: 아니요.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "'''{review}'''\n",
    "\n",
    "위의 문장은 분노를 표현하고 있는가요? '예' 또는 '아니요'로 알려줘.\n",
    "\"\"\"\n",
    "response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_2_70B_CHAT,  decoding_method=\"greedy\", max_new_tokens=10,\n",
    "                              min_new_tokens=1, temperature=0, repetition_penalty=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc926d-33f0-4987-946b-293f7dc858c7",
   "metadata": {},
   "source": [
    "#### Q4) 구매한 상품과 회사 이름을 추출하고 JSON 형식으로 반환하세요.\n",
    "대상 답변 = product[침실 램프], name[Lumina]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d85776-8564-419f-9bf8-3f4836075cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"name\": \"Lumina\",\n",
      "\"product\": \"침실 램프\"\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "'''{review}'''\n",
    "\n",
    "위 단락을 기반으로 리뷰된 제품의 이름과 해당 제품을 판매하는 회사의 이름을 찾으세요.\n",
    "찾은 이름을 사용하여 JSON을 작성하세요.\n",
    "\n",
    "\"\"\"\n",
    "response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_2_70B_CHAT,  decoding_method=\"greedy\", max_new_tokens=33,\n",
    "                              min_new_tokens=1, temperature=0, repetition_penalty=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c901b1-3021-4f3a-b194-d81539acf161",
   "metadata": {},
   "source": [
    "#### Q5) 여러가지 프롬프트로 결합하고 JSON으로 반환하세요\n",
    "대상 답변 = positive[true], Anger[false], Brand[Lumina]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de9e5a3d-5ef0-41b7-84f3-19b460f5f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "\"positive_sentiment\": true,\n",
      "\"angry\": false,\n",
      "\"company_name\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "'''{review}'''\n",
    "\n",
    "위 리뷰를 기반으로 다음 질문에 대한 답을 찾으세요.\n",
    "\n",
    "리뷰에 긍정적인 감정이 있는지 여부를 찾으세요.\n",
    "리뷰 작성자가 분노를 표현했는지 여부를 찾으세요.\n",
    "리뷰된 제품을 판매하는 회사의 이름을 찾으세요.\n",
    "이에 대한 답으로 JSON을 작성하세요.\n",
    "\"\"\"\n",
    "response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_2_70B_CHAT,  decoding_method=\"greedy\", max_new_tokens=45,\n",
    "                              min_new_tokens=1, temperature=0, repetition_penalty=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e22aac4-f1d6-46cd-ab98-75c15a48afe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f516b7-a28f-4397-88a6-e0e24a0bb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"딸의 생일을 위해 이 판다 인형을 샀습니다. \\\n",
    "딸이 그것을 정말 좋아하고 어디든 가져다 놉니다. \\\n",
    "부드럽고 귀여워서 얼굴도 친근한 느낌이에요. \\\n",
    "그러나 내가 지불한 가격에 비해 조금 작은 편이에요. \\\n",
    "동일한 가격으로 더 큰 옵션이 있을거 같아요. \\\n",
    "예상보다 하루 일찍 도착해서 딸에게 선물하기 전에 제가 직접 놀 수 있었어요.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c6ff0f-9dc5-447e-ada3-9b0adb642b9e",
   "metadata": {},
   "source": [
    "\n",
    "#### Q6) 다음 제품 리뷰를 요약하세요.\n",
    "예시 요약 = \n",
    "* 딸의 생일 선물로 판다 인형을 샀는데, 딸이 정말 좋아하고 가져다 놉니다.\n",
    "* 인형이 부드럽고 귀여워서 얼굴도 친근한 느낌이에요.\n",
    "* 하지만 내가 지불한 가격에 비해 조금 작은 편이에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83382cd0-4780-46b7-bd03-1e69bb721eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* 딸의 생일 선물로 판다 인형을 샀는데, 딸이 정말 좋아하고 가져다 놉니다.\n",
      "* 인형이 부드럽고 귀여워서 얼굴도 친근한 느낌이에요.\n",
      "* 하지만 내가 지불한 가격에 비해 조금 작은 편이에요.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "'''{review}'''\n",
    "\n",
    "위의 리뷰를 기반으로 한국어 요약을 작성해주세요.\n",
    "최대 3문장으로 작성해주세요.\n",
    "\"\"\"\n",
    "\n",
    "response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_2_70B_CHAT, decoding_method=\"greedy\", max_new_tokens=200,\n",
    "                              min_new_tokens=30, repetition_penalty=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37f27b-0670-4153-a3ba-cefbec061173",
   "metadata": {},
   "source": [
    "#### Q7) 동일한 제품 리뷰를 배송 부서의 관점에서 요약하라. \n",
    "예시 요약 = \n",
    "* 주문이 정시에 도착했습니다.\n",
    "* 수령한 패키지가 손상되지 않았습니다.\n",
    "* 예상보다 하루 일찍 도착해서 딸에게 선물하기 전에 제가 직접 놀 수 있었어요.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5d1ba92-3eec-4572-823d-ef4d257812cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "배송 요약:\n",
      "\n",
      "* 주문이 정시에 도착하였습니다.\n",
      "* 수령한 패키지가 손상되지 않았습니다.\n",
      "* 예상보다 하루 일찍 도착해서 딸에게 선물하기 전에 제가 직접 놀 수 있었어요.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "'''{review}'''\n",
    "\n",
    "위의 리뷰를 기반으로 배송과 관련된 요약을 '한국어'로 작성해 보세요.\n",
    "주문이 정시에 도착했는지의 여부, 수령한 패키지가 손상되었는지 여부 등이 있습니다.\n",
    "최대 3문장으로 작성해주세요.\n",
    "\"\"\"\n",
    "\n",
    "response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_2_70B_CHAT, decoding_method=\"greedy\", max_new_tokens=200,\n",
    "                              min_new_tokens=30, repetition_penalty=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f50c969-8970-42bc-841c-60a256a415ef",
   "metadata": {},
   "source": [
    "#### Q8) 개인 정보 식별 제거. \n",
    "다음 이메일이 주어지면 개인 식별 정보 (예: 이름, 이메일 등)를 제거하기 위한 프롬프트를 작성하십시오.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce42a21-3c8a-4e06-85f6-c1704c44b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "email=\"\"\"\n",
    "안녕하세요 존,\n",
    "\n",
    "저는 최근에 새 차를 구입한 것을 알게 되어서 당신에게 편지를 씁니다. \n",
    "저는 지역 딜러쉽 (Cheap Dealz)에서 영업 사원으로 일하고 있으며 새 차에 대한 훌륭한 거래가 있다는 것을 알려드리고 싶었습니다. \n",
    "관심이 있으시면 알려주시기 바랍니다.\n",
    "\n",
    "감사합니다,\n",
    "\n",
    "전화: 410-805-2345\n",
    "이메일: jimmysmith@cheapdealz.com\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66557a60-0db9-40d8-aa25-f2a460fe3895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "안녕하세요,\n",
      "\n",
      "저는 최근에 새 차를 구입한 것을 알게 되어서 당신에게 편지를 씁니다. \n",
      "저는 지역 딜러쉽 (Cheap Dealz)에서 영업 사원으로 일하고 있으며 새 차에 대한 훌륭한 거래가 있다는 것을 알려드리고 싶었습니다. \n",
      "관심이 있으시면 알려주시기 바랍니다.\n",
      "\n",
      "감사합니다\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "email: ```{email}```\n",
    "\n",
    "위의 이메일을 기반으로 다음과 같이 사람 이름, 주소, 전화번호, 휴대폰 번호, 이메일, 신용카드 번호, 의료 정보 등 민감한 정보를 삭제하여 이메일을 다시 만들어주세요.\n",
    "\n",
    "새 이메일:\n",
    "\"\"\"\n",
    "# response = send_to_watsonxai(prompts=[prompt])\n",
    "# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n",
    "response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_2_70B_CHAT, decoding_method=\"greedy\", max_new_tokens=235,\n",
    "                              min_new_tokens=1, repetition_penalty=1.0, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86351bcc-3c74-4fb3-a414-60d1e6b81b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
